{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3de5dbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from box import Box\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820dd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"/home/deeplearning/Dev/Ultrasound/ContourDetection/ultrasound_ge/\")\n",
    "sys.path.insert(0, \"C:\\\\Dev\\\\ContourDetectionGCN\\\\gcn_ultrasound_segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f453466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import load_model\n",
    "from CVUSInference.Utilities.model_profiler import profile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "656d40d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading network type: VAEGCN..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using inference model so image_decoder will not be included in forward pass\n",
      "loading network type: VAEGCN..\n",
      "using inference model so image_decoder will not be included in forward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading network type: VAEGCN..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using inference model so image_decoder will not be included in forward pass\n",
      "loading network type: VAEGCN..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using inference model so image_decoder will not be included in forward pass\n",
      "loading network type: VAEGCN..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using inference model so image_decoder will not be included in forward pass\n",
      "loading network type: VAEGCN..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\212686118/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using inference model so image_decoder will not be included in forward pass\n"
     ]
    }
   ],
   "source": [
    "resnet18 = load_model(\"VAEGCN\", nb_classes=12, feature_vector_size=128, backbone=18, is_gpu=True, inference_model=True)\n",
    "resnet18 = resnet18.cuda()\n",
    "mobilenet = load_model(\"VAEGCN\", nb_classes=12, feature_vector_size=128, backbone=\"mobilenet\", is_gpu=True, inference_model=True)\n",
    "mobilenet = mobilenet.cuda()\n",
    "densenet201 = load_model(\"VAEGCN\", nb_classes=12, feature_vector_size=128, backbone=\"densenet201\", is_gpu=True, inference_model=True)\n",
    "densenet201 = densenet201.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f4022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "shape_3_224 = (3, 224, 224)\n",
    "shape_3_128 = (3, 128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d8d58",
   "metadata": {},
   "source": [
    "## Profile with `224x224` then `128x128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "689d1263",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>parameters</th>\n",
       "      <th>GFlops</th>\n",
       "      <th>cpu time total</th>\n",
       "      <th>self cpu time total</th>\n",
       "      <th>cuda time total</th>\n",
       "      <th>self cuda time total</th>\n",
       "      <th>cuda memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>(3, 224, 224)</td>\n",
       "      <td>13839333</td>\n",
       "      <td>3.628680</td>\n",
       "      <td>43.411ms</td>\n",
       "      <td>13.904ms</td>\n",
       "      <td>173.444ms</td>\n",
       "      <td>77.967ms</td>\n",
       "      <td>183974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>(3, 224, 224)</td>\n",
       "      <td>5722277</td>\n",
       "      <td>0.600762</td>\n",
       "      <td>53.838ms</td>\n",
       "      <td>21.450ms</td>\n",
       "      <td>357.501ms</td>\n",
       "      <td>163.200ms</td>\n",
       "      <td>197688320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>(3, 224, 224)</td>\n",
       "      <td>22287653</td>\n",
       "      <td>8.580449</td>\n",
       "      <td>203.718ms</td>\n",
       "      <td>84.140ms</td>\n",
       "      <td>937.031ms</td>\n",
       "      <td>712.426ms</td>\n",
       "      <td>694176256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>(3, 128, 128)</td>\n",
       "      <td>13839333</td>\n",
       "      <td>1.185924</td>\n",
       "      <td>39.863ms</td>\n",
       "      <td>12.409ms</td>\n",
       "      <td>151.637ms</td>\n",
       "      <td>68.193ms</td>\n",
       "      <td>132940288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MobileNet</td>\n",
       "      <td>(3, 128, 128)</td>\n",
       "      <td>5722277</td>\n",
       "      <td>0.197216</td>\n",
       "      <td>50.013ms</td>\n",
       "      <td>20.053ms</td>\n",
       "      <td>326.927ms</td>\n",
       "      <td>150.815ms</td>\n",
       "      <td>65788416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DenseNet</td>\n",
       "      <td>(3, 128, 128)</td>\n",
       "      <td>22287653</td>\n",
       "      <td>2.802828</td>\n",
       "      <td>208.945ms</td>\n",
       "      <td>86.676ms</td>\n",
       "      <td>2.400s</td>\n",
       "      <td>788.239ms</td>\n",
       "      <td>243157504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model    input_shape  parameters    GFlops cpu time total  \\\n",
       "0   ResNet18  (3, 224, 224)    13839333  3.628680       43.411ms   \n",
       "1  MobileNet  (3, 224, 224)     5722277  0.600762       53.838ms   \n",
       "2   DenseNet  (3, 224, 224)    22287653  8.580449      203.718ms   \n",
       "3   ResNet18  (3, 128, 128)    13839333  1.185924       39.863ms   \n",
       "4  MobileNet  (3, 128, 128)     5722277  0.197216       50.013ms   \n",
       "5   DenseNet  (3, 128, 128)    22287653  2.802828      208.945ms   \n",
       "\n",
       "  self cpu time total cuda time total self cuda time total  cuda memory  \n",
       "0            13.904ms       173.444ms             77.967ms    183974400  \n",
       "1            21.450ms       357.501ms            163.200ms    197688320  \n",
       "2            84.140ms       937.031ms            712.426ms    694176256  \n",
       "3            12.409ms       151.637ms             68.193ms    132940288  \n",
       "4            20.053ms       326.927ms            150.815ms     65788416  \n",
       "5            86.676ms          2.400s            788.239ms    243157504  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = []\n",
    "for input_shape in [shape_3_224, shape_3_128]:\n",
    "    for m, model in zip([\"ResNet18\", \"MobileNet\", \"DenseNet\"], [resnet18, mobilenet, densenet201]):\n",
    "        res = dict(model=m, input_shape=input_shape)\n",
    "        res.update(profile_model(model, (batch_size, *input_shape), print_res=False, use_cuda=True))\n",
    "        profiles.append(res)\n",
    "prof_df = pd.DataFrame(profiles)\n",
    "prof_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9427d8f",
   "metadata": {},
   "source": [
    "# ONNX export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1165186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_model_dir = \"./onnx_models\"\n",
    "if not os.path.exists(ONNX_model_dir):\n",
    "    os.makedirs(ONNX_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13690ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input_3_224 = torch.zeros((1, *shape_3_224)).cuda()\n",
    "dummy_input_3_128 = torch.zeros((1, *shape_3_128)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f61dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(resnet18,               # model being run\n",
    "                  dummy_input_3_224,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"resnet18_3x224x224_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )\n",
    "\n",
    "torch.onnx.export(resnet18,               # model being run\n",
    "                  dummy_input_3_128,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"resnet18_3x128x128_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4192ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(mobilenet,               # model being run\n",
    "                  dummy_input_3_224,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"mobilenet_3x224x224_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )\n",
    "\n",
    "torch.onnx.export(mobilenet,               # model being run\n",
    "                  dummy_input_3_128,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"mobilenet_3x128x128_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1817a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(densenet201,               # model being run\n",
    "                  dummy_input_3_224,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"densenet201_3x224x224_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )\n",
    "\n",
    "torch.onnx.export(densenet201,               # model being run\n",
    "                  dummy_input_3_128,                         # model input (or a tuple for multiple inputs)\n",
    "                  os.path.join(ONNX_model_dir, \"densenet201_3x128x128_opset11.onnx\"),   # where to save the model\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc46c59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [\"a\", \"b\", \"d\"]\n",
    "b = c.pop(-1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cee922c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309abd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}